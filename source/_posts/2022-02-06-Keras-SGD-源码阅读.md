---
title: 2022-02-06-Keras SGD 源码阅读
date: 2022-02-06 17:15:23
tags:
categories:
mathjax: true
---

摘要

<!-- more -->

## 缘起


Keras代码中 nesterov SGD算法的实现看起来和一些论文、博客中的公式不相同。


## 现象

核心代码块

```python
# from keras code: keras.optimizer_v1.SGD 
for p, g, m in zip(params, grads, moments):
    v = self.momentum * m - lr * g    # velocity
    self.updates.append(tf.compat.v1.assign(m, v))
    if self.nesterov:
        new_p = p + self.momentum * v - lr * g
    else:
        new_p = p + v
```

## 相关的博客和讨论

1. 问题
    1. [Question about Nesterov momentum implementation · Issue #14115 · keras-team/keras](https://github.com/keras-team/keras/issues/14115)
    2. [Nesterov based gradient descent · Issue #966 · keras-team/keras](https://github.com/keras-team/keras/issues/966)
    3. [New PR for Nesterov change by the-moliver · Pull Request #47 · pluskid/Mocha.jl](https://github.com/pluskid/Mocha.jl/pull/47)
2. 一些相关的课程
    1. [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/neural-networks-3/#sgd)
    2. [ADVANCES IN OPTIMIZING RECURRENT NETWORKS 1212.0901v2.pdf](https://arxiv.org/pdf/1212.0901v2.pdf )
3. [比Momentum更快：揭开Nesterov Accelerated Gradient的真面目 - 知乎](https://zhuanlan.zhihu.com/p/22810533)

## 我的理解

1. 本质上 是用了公式 
2. 

$\hat{d_i} = \beta^2 d_{i-1} + (\beta + 1) g(\theta_{i-1})$



## 参考资料

1. keras.optimizer_v1.SGD 
2. [Question about Nesterov momentum implementation · Issue #14115 · keras-team/keras](https://github.com/keras-team/keras/issues/14115)
3. [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/neural-networks-3/#sgd)
4. [Nesterov based gradient descent · Issue #966 · keras-team/keras](https://github.com/keras-team/keras/issues/966)
5. [New PR for Nesterov change by the-moliver · Pull Request #47 · pluskid/Mocha.jl](https://github.com/pluskid/Mocha.jl/pull/47)
